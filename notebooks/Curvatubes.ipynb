{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use this script\n",
    "\n",
    "Run all the cells before Section \"Experiment 2\". From there, you can run one of the following experiments independently:\n",
    "\n",
    "- (**Exp 1** - Willmore validation : not here but in the other notebook)\n",
    "- **Exp 2** - Generates a single shape (and shows how to track the convergence)\n",
    "- **Exp 3** - Bilinear interpolation\n",
    "- **Exp 4** - Generate random shapes and plot them in UMAP\n",
    "\n",
    "The notebook also contains a few extensions:\n",
    "\n",
    "- **Ext 1** - Orientation\n",
    "- **Ext 2** - Spatialization\n",
    "\n",
    "For more details, please refer to my paper [here](https://arxiv.org/abs/2103.04856)!\n",
    "\n",
    "**If you find any problem in this script**, please contact me at a.song19@imperial.ac.uk.\n",
    "Good luck for generating beautiful shapes! If you get interesting shapes that have not been featured\n",
    "in the paper and want to show them to me, I will be happy to discuss about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.3 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/usr/lib/python3/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/usr/lib/python3/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n",
      "    app.start()\n",
      "  File \"/usr/lib/python3/dist-packages/ipykernel/kernelapp.py\", line 677, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/usr/lib/python3/dist-packages/tornado/platform/asyncio.py\", line 199, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/usr/lib/python3/dist-packages/ipykernel/kernelbase.py\", line 461, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/usr/lib/python3/dist-packages/ipykernel/kernelbase.py\", line 450, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/usr/lib/python3/dist-packages/ipykernel/kernelbase.py\", line 357, in dispatch_shell\n",
      "    await result\n",
      "  File \"/usr/lib/python3/dist-packages/ipykernel/kernelbase.py\", line 652, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/usr/lib/python3/dist-packages/ipykernel/ipkernel.py\", line 353, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/usr/lib/python3/dist-packages/ipykernel/zmqshell.py\", line 532, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\", line 2914, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\", line 2960, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/usr/lib/python3/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\", line 3185, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\", line 3377, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_18176/1780767238.py\", line 9, in <module>\n",
      "    import matplotlib.pyplot as plt\n",
      "  File \"/usr/lib/python3/dist-packages/matplotlib/__init__.py\", line 109, in <module>\n",
      "    from . import _api, _version, cbook, docstring, rcsetup\n",
      "  File \"/usr/lib/python3/dist-packages/matplotlib/rcsetup.py\", line 27, in <module>\n",
      "    from matplotlib.colors import Colormap, is_color_like\n",
      "  File \"/usr/lib/python3/dist-packages/matplotlib/colors.py\", line 56, in <module>\n",
      "    from matplotlib import _api, cbook, scale\n",
      "  File \"/usr/lib/python3/dist-packages/matplotlib/scale.py\", line 23, in <module>\n",
      "    from matplotlib.ticker import (\n",
      "  File \"/usr/lib/python3/dist-packages/matplotlib/ticker.py\", line 136, in <module>\n",
      "    from matplotlib import transforms as mtransforms\n",
      "  File \"/usr/lib/python3/dist-packages/matplotlib/transforms.py\", line 46, in <module>\n",
      "    from matplotlib._path import (\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core.multiarray failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_18176/1780767238.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclear_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mformatted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'.3f'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;31m# cbook must import matplotlib only within function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;31m# definitions, so it is safe to import from it here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_api\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcsetup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcbook\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMatplotlibDeprecationWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msanitize_sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcbook\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmplDeprecation\u001b[0m  \u001b[0;31m# deprecated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/matplotlib/rcsetup.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_api\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcbook\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mls_mapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mColormap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_color_like\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfontconfig_pattern\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mparse_fontconfig_pattern\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enums\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mJoinStyle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCapStyle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/matplotlib/colors.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmpl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_api\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_color_data\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBASE_COLORS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTABLEAU_COLORS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCSS4_COLORS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXKCD_COLORS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/matplotlib/scale.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmpl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_api\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m from matplotlib.ticker import (\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mNullFormatter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mScalarFormatter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLogFormatterSciNotation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLogitFormatter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mNullLocator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLogLocator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoLocator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoMinorLocator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/matplotlib/ticker.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmpl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_api\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtransforms\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0m_log\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/matplotlib/transforms.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_api\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m from matplotlib._path import (\n\u001b[0m\u001b[1;32m     47\u001b[0m     affine_transform, count_bboxes_overlapping_bbox, update_path_extents)\n\u001b[1;32m     48\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: numpy.core.multiarray failed to import"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import string\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "def formatted(f): return format(f, '.3f').rstrip('0').rstrip('.')\n",
    "\n",
    "import torch\n",
    "dtype = torch.cuda.FloatTensor # we work with GPUs # if torch.cuda.is_available() else torch.FloatTensor\n",
    "\n",
    "# curvatubes imports\n",
    "from cvtub.utils import slices, single, load_nii, save_nii, random_init, init_balls\n",
    "from cvtub.energy import discrepancy, ratio_discr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main generator function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_12370/3127234347.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcvtub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_generate_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m def generate(A0, params, M0, delta_x, maxeval = 10000, snapshot_folder = '', exp_title = '',\n",
      "\u001b[0;32m~/PycharmProjects/curvatubes/cvtub/generator.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcvtub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msave_nii\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproject_average\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "# Main function that generates 3D shapes with curvatubes\n",
    "\n",
    "# optimizer: Adam\n",
    "# flow type: conservative H^{-1}\n",
    "# periodic boundary conditions\n",
    "\n",
    "\n",
    "from cvtub.generator import _generate_shape\n",
    "\n",
    "def generate(A0, params, M0, delta_x, maxeval = 10000, snapshot_folder = '', exp_title = '',\n",
    "             display_all = True, check_viable = False, cond_take_snapshot = None) :  \n",
    "    \n",
    "    '''Optimizes the phase-field Feps(u) ( see paper / see comments in cvtub/energy.py ) '''\n",
    "    \n",
    "    xi =  1e-6\n",
    "    flow_type = 'cons'\n",
    "    mode = 'periodic'\n",
    "    optim_method = 'adam'\n",
    "    sigma_blur = 2\n",
    "    Z,X,Y = A0[0].shape\n",
    "\n",
    "    optim_props = {'maxeval': maxeval, 'sigma_blur': sigma_blur, 'lr': .001, 'eps_adam' : 1e-2, \n",
    "                   'betas' : (0.9,0.999), 'weight_decay' : 0, 'amsgrad' : False,\n",
    "                   'display_it_nb' : 1000, 'fill_curve_nb' : 50}\n",
    "    \n",
    "    u = _generate_shape(A0, params, delta_x, xi, optim_method, optim_props, flow_type, mode,\n",
    "                               M0 = M0, snapshot_folder = snapshot_folder, exp_title = exp_title, \n",
    "                                cond_take_snapshot = cond_take_snapshot, display_all = display_all, \n",
    "                                check_viable = check_viable)\n",
    "    \n",
    "    if check_viable == True :\n",
    "        u, viable_bool = u\n",
    "        return u.detach().cpu().numpy(), viable_bool\n",
    "\n",
    "    return u.detach().cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function which plots the curvature diagram of a shape \n",
    "# defined as the zero level set of a phase-field u\n",
    "\n",
    "from cvtub.curvdiags import kap_eps, curvhist, density_scatter\n",
    "\n",
    "def plot_curvature_diagram(u, save = True, save_name = 'curvature_diagram.png'):\n",
    "\n",
    "    kap1_eps, kap2_eps = kap_eps(u)\n",
    "\n",
    "    kap1_vals, kap2_vals, areas = \\\n",
    "    curvhist(u, kap1_eps, kap2_eps, delta_x = 0.01, show_figs = False)\n",
    "\n",
    "    x,y = np.clip(kap1_vals, -100,100), np.clip(kap2_vals, -100, 100)\n",
    "    density_scatter(x,y, areas, showid = True, equalaxis = True, \n",
    "                    bins = 100, xlabel = 'kap1', \n",
    "                    ylabel = 'kap2', save = save, save_name = save_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can stop here, and then run individual experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2 - Generate a single shape\n",
    "\n",
    "**Generate** shapes with `generate()`.\n",
    "\n",
    "We work with a vector field A instead of the scalar field u itself, because the $H^{-1}$ flow in u\n",
    "translates into a $L^2$ flow in A (see the paper). The main parameters are\n",
    "\n",
    "- ```params = eps, a20, a11, a02, b10, b01, c```, where\n",
    "    - `eps` is the **phase-transition parameter**\n",
    "    - `a20, a11, a02, b10, b01, c` are the **polynomial coefficients** in the curvature functional\n",
    "\n",
    "\n",
    "- the **mass** `M0`, which is the imposed average of the phase-field *u*\n",
    "- `MAXEVAL`, the nb of iterations of the algorithm. In the paper, I chose 8000 to be very secure, but you can actually take 4000 (sufficient) or even 1000 (approximate shape).\n",
    "\n",
    "> *Remarks*:\n",
    "> - in the paper, the term \"generation parameters\" refers to the tuple `(a20, a11, a02, b10, b01, c, M0)`\n",
    "> -  to include orientation, or use spatialized parameters, see **Ext 1** and **Ext 2**.\n",
    "\n",
    "**Visualize its curvature diagram** with `plot_curvature_diagram()`.\n",
    "\n",
    "You can plot the curvature diagrams, i.e., the histograms of the diffuse principal curvatures `(kap1_eps, kap2_eps)`.\n",
    "\n",
    "**Export the phase-field $u$** into `.nii.gz` format with `save_nii()`.\n",
    "\n",
    "You can then visualize the level set $\\{u = 0\\}$ for instance in Paraview or 3DSlicer.\\\n",
    "You can also visualize $u$ or $\\{u = 0\\}$ in the notebook itself using [pyvista](https://docs.pyvista.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some folders to save the results\n",
    "\n",
    "niifolder = '../results/Experiment_2/'\n",
    "curvesfolder = niifolder + 'Curves/'\n",
    "diagsfolder = niifolder + 'Diagrams/'\n",
    "\n",
    "if not os.path.exists(niifolder):\n",
    "    print(niifolder + ' folder does not exist, creating it...')\n",
    "    os.makedirs(niifolder)\n",
    "if not os.path.exists(curvesfolder):\n",
    "    print('Curves subfolder does not exist, creating it...')\n",
    "    os.makedirs(curvesfolder)\n",
    "if not os.path.exists(diagsfolder):\n",
    "    print('Diagrams subfolder does not exist, creating it...')\n",
    "    os.makedirs(diagsfolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Number of iterations?\n",
    "MAXEVAL = 4000 \n",
    "# 4000 are generally sufficient, 8000 are over-sufficient\n",
    "\n",
    "# Sizes\n",
    "Z,X,Y = 100,100,100\n",
    "delta_x = 1/100\n",
    "\n",
    "# Initialize A = A0: a random vector field with values in R^3\n",
    "A0 = 40 * delta_x * np.random.rand(3,Z,X,Y)\n",
    "A0 = torch.Tensor(A0).type(dtype)\n",
    "slices(A0[0]) # show three 2D slices of the 3D scalar field A0[0] \n",
    "\n",
    "# Parameters\n",
    "eps = 0.02\n",
    "a20, a11, a02, b10, b01, c = 1, 0.85, 6, -80, -7.5, 1770\n",
    "M0 = -0.42\n",
    "params = eps, a20, a11, a02, b10, b01, c\n",
    "\n",
    "# Generate the shape - you will see slices of u along the iterations, and the loss curves are saved in their folder\n",
    "u = generate(A0, params, M0, delta_x, maxeval = MAXEVAL, snapshot_folder = niifolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save u as a .nii.gz file\n",
    "str_tup = tuple([ formatted(x) for x in [eps, a20, a11, a02, b10, b01, c, M0]])\n",
    "name = 'eps {} coeffs [{}, {}, {}, {}, {}, {}] m {}'.format(*str_tup)\n",
    "print(name)\n",
    "save_nii(np.floor(100 * u) / 100, niifolder + name) # or u if you have more space\n",
    "\n",
    "# Plot and save its curvature diagram\n",
    "plot_curvature_diagram(u, save = True, save_name = diagsfolder + name + ' kap1_kap2.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to keep track of the convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define at which iterations you want to save the current u as a .nii.gz file\n",
    "\n",
    "def cond_take_snapshot(iteration):\n",
    "    if iteration in [10, 100, 200, 400, 1000, 2000, 4000] :\n",
    "        return True\n",
    "\n",
    "u, A = generate(A0, params, M0, delta_x, maxeval = 4001, snapshot_folder = niifolder, cond_take_snapshot = cond_take_snapshot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 3 - Bilinear interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some folders to save the results\n",
    "\n",
    "niifolder = '../results/Experiment_3/'\n",
    "curvesfolder = niifolder + 'Curves/'\n",
    "diagsfolder = niifolder + 'Diagrams/'\n",
    "\n",
    "if not os.path.exists(niifolder):\n",
    "    print(niifolder + ' folder does not exist, creating it...')\n",
    "    os.makedirs(niifolder)\n",
    "if not os.path.exists(curvesfolder):\n",
    "    print('Curves subfolder does not exist, creating it...')\n",
    "    os.makedirs(curvesfolder)\n",
    "if not os.path.exists(diagsfolder):\n",
    "    print('Diagrams subfolder does not exist, creating it...')\n",
    "    os.makedirs(diagsfolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bilinear interpolation between the generation parameters of\n",
    "# 4 ref shape textures: layers, spheres, tubes, sponges\n",
    "# All simulations start from the same A0\n",
    "\n",
    "from cvtub.utils import convert_params\n",
    "    \n",
    "# nb of iterations in the algorithm\n",
    "MAXEVAL = 4000 # 8000 in the paper\n",
    "\n",
    "# sizes\n",
    "Z,X,Y = 100,100,100\n",
    "eps = 0.02\n",
    "delta_x = 1/100\n",
    "\n",
    "# layers\n",
    "M0 = -0.3\n",
    "h2,H0,k1,s,kap1_0,t,kap2_0 = 1,0,0,1,0,1,0\n",
    "a20, a11, a02, b10, b01, c = convert_params(h2,H0,k1,s,kap1_0,t,kap2_0)\n",
    "pm_layers = eps, a20, a11, a02, b10, b01, c, M0\n",
    "\n",
    "# spheres\n",
    "M0 = -0.6\n",
    "R = 0.08\n",
    "h2,H0,k1,s,kap1_0,t,kap2_0 = 1,2/R,0,1,1/R,1,1/R\n",
    "a20, a11, a02, b10, b01, c = convert_params(h2,H0,k1,s,kap1_0,t,kap2_0)\n",
    "pm_spheres = eps, a20, a11, a02, b10, b01, c, M0\n",
    "\n",
    "# tubes\n",
    "M0 = -0.7\n",
    "r = 0.04\n",
    "h2,H0,k1,s,kap1_0,t,kap2_0 = 1,1/r,0,1,1/r,10,0\n",
    "a20, a11, a02, b10, b01, c = convert_params(h2,H0,k1,s,kap1_0,t,kap2_0)\n",
    "pm_tubes = eps, a20, a11, a02, b10, b01, c, M0\n",
    "\n",
    "# sponges\n",
    "M0 = -0.25\n",
    "h2,H0,k1,s,kap1_0,t,kap2_0 = 1,5,0.8,0,0,1,0\n",
    "a20, a11, a02, b10, b01, c = convert_params(h2,H0,k1,s,kap1_0,t,kap2_0)\n",
    "pm_sponges = eps, a20, a11, a02, b10, b01, c, M0\n",
    "\n",
    "surnames = ['layers','spheres','tubes','sponges']\n",
    "pms = [pm_layers, pm_spheres, pm_tubes, pm_sponges]\n",
    "\n",
    "for i in range(4) :\n",
    "    print(surnames[i])\n",
    "    print(pms[i])\n",
    "    \n",
    "x1, x2 = 0, 1\n",
    "y1, y2 = 0, 1\n",
    "\n",
    "n = 4 # nb of intervals between endpoints (n = 4 in the paper)\n",
    "\n",
    "q11 = np.array(pm_layers)[None,None,:]\n",
    "q12 = np.array(pm_spheres)[None,None,:]\n",
    "q22 = np.array(pm_tubes)[None,None,:]\n",
    "q21 = np.array(pm_sponges)[None,None,:]\n",
    "\n",
    "x,y = np.mgrid[0:1:(n+1)*1j, 0:1:(n+1)*1j] # is,js convention\n",
    "x = x[:,:,None] \n",
    "y = y[:,:,None]\n",
    "\n",
    "# bilinear interpolation of the parameters (eps, [coeffs], M0)\n",
    "pms_interp = ( q11 * (x2 - x) * (y2 - y) + q21 * (x - x1) * (y2 - y) + q12 * (x2 - x) * (y - y1) + q22 * (x - x1) * (y - y1) ) / ((x2 - x1) * (y2 - y1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize A0 (the same for all)\n",
    "\n",
    "A0 = 40 * delta_x * np.random.rand(3,Z,X,Y) # 20 or 40 * delta_x * ...\n",
    "A0 = torch.Tensor(A0).type(dtype)\n",
    "\n",
    "# Generate bilinear interpolation now!\n",
    "\n",
    "for i in range(n+1) :\n",
    "    for j in range(n+1) :\n",
    "        \n",
    "        # Specify and save parameter values\n",
    "        params = pms_interp[i,j,:-1]\n",
    "        M0 = pms_interp[i,j,-1]\n",
    "        a20, a11, a02, b10, b01, c = params[1:7]\n",
    "        \n",
    "        print('I,J = {},{}'.format(i,j))\n",
    "        print('Coeffs {} '.format(params[1:7]))\n",
    "        print('Mass {} '.format(M0))\n",
    "\n",
    "        file_object = open(niifolder + 'meta.txt', 'a')\n",
    "        file_object.write('I,J = {},{} \\n'.format(i,j))\n",
    "        file_object.write('eps {} \\n'.format(eps))\n",
    "        file_object.close()\n",
    "\n",
    "        u = generate(A0, params, M0, delta_x, maxeval = MAXEVAL, snapshot_folder = niifolder, exp_title = 'I {} J {} '.format(i,j))\n",
    "\n",
    "        str_tup = tuple([ formatted(x) for x in [a20, a11, a02, b10, b01, c, M0]])\n",
    "        name = 'I {} J {} coeffs [{} {} {} {} {} {}] m {}'.format(i,j,*str_tup)\n",
    "        print(name)\n",
    "        \n",
    "        # Save u as a .nii.gz file\n",
    "        save_nii(np.floor(100 * u) / 100, niifolder + name) # or u, if you have more space\n",
    "\n",
    "        # Plot and save its curvature diagram\n",
    "        plot_curvature_diagram(u, save = True, save_name = diagsfolder + name + ' kap1_kap2.png')\n",
    "\n",
    "        clear_output()\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 4 - Generate random shapes and plot them in UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some folders to save the results\n",
    "\n",
    "niifolder = '../results/Experiment_4/'\n",
    "curvesfolder = niifolder + 'Curves/'\n",
    "diagsfolder = niifolder + 'Diagrams/'\n",
    "\n",
    "if not os.path.exists(niifolder):\n",
    "    print(niifolder + ' folder does not exist, creating it...')\n",
    "    os.makedirs(niifolder)\n",
    "if not os.path.exists(curvesfolder):\n",
    "    print('Curves subfolder does not exist, creating it...')\n",
    "    os.makedirs(curvesfolder)\n",
    "if not os.path.exists(diagsfolder):\n",
    "    print('Diagrams subfolder does not exist, creating it...')\n",
    "    os.makedirs(diagsfolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some functions to visualize the final plot...\n",
    "\n",
    "import umap\n",
    "import hdbscan\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "def give_color_array(nb_clusters) : \n",
    "    # gives a collection of colors to make nice legends\n",
    "    colors1 = plt.cm.tab20b(np.linspace(0., 1, 128))\n",
    "    colors2 = plt.cm.tab20c(np.linspace(0, 1, 128))\n",
    "    colors = np.vstack((colors1, colors2))\n",
    "    mymap = mcolors.LinearSegmentedColormap.from_list('my_colormap', colors)\n",
    "    cm = plt.get_cmap(mymap)\n",
    "    colors = [cm(1.*i/nb_clusters) for i in range(nb_clusters)]\n",
    "    return colors\n",
    "\n",
    "def SCAN_cluster(umap_embedding) : # shape (nb of points, dimension) \n",
    "    clustering = hdbscan.HDBSCAN(\n",
    "        min_samples = 10,\n",
    "        min_cluster_size = 10)\n",
    "    labels = clustering.fit_predict(umap_embedding)\n",
    "    return labels\n",
    "\n",
    "def scatter_atlas(points, labels, title_string = '', save = True, folder = '', \n",
    "                        size = 3, markerscale = 5) :\n",
    "    L = len(points)\n",
    "    unique_labels = np.unique(labels) # labels included between 0 and L-1\n",
    "    colors = give_color_array(len(unique_labels))\n",
    "        \n",
    "    plt.figure(figsize=(12,12))\n",
    "    ax = plt.gca()    \n",
    "\n",
    "    for i,l in enumerate(unique_labels) :\n",
    "        wh = np.where(labels == l)[0]\n",
    "        col = np.repeat(np.array(colors[i])[None], len(wh), axis = 0)\n",
    "        ax.scatter(points[wh,0], points[wh,1], s=size, c= col, label = l, edgecolors='none')\n",
    "\n",
    "    ax.set_title(title_string, fontsize=20)\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "    box = ax.get_position()\n",
    "    ax.set_position([box.x0, box.y0, box.width * 0.75, box.height]) # 0.75 good for 30 labels\n",
    "    ax.legend(loc='center left', bbox_to_anchor=(1, 0.5), markerscale = markerscale, prop = {'size':10})\n",
    "    if save :\n",
    "        plt.savefig(folder + title_string + '.png', dpi=200)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We generate random shapes by choosing random coefficients and only keeping viable shapes.\n",
    "# The pairwise Wasserstein distances are computed between all pairs of shapes with geomloss \n",
    "#                            https://www.kernel-operations.io/geomloss/\n",
    "# and UMAP embeds the dataset into a 2D atlas of shape textures.\n",
    "#                            https://umap-learn.readthedocs.io/en/latest/\n",
    "\n",
    "\n",
    "MAXEVAL = 8000 # 8000 in the paper.\n",
    "nb_shapes = 10 # nb_shapes = 1000 in the paper\n",
    "# P.S.: add some more zeros if you want to spend 3 days in it :) \n",
    "\n",
    "# Sizes\n",
    "Z,X,Y = 100,100,100\n",
    "delta_x = 1/100\n",
    "eps = 0.02\n",
    "\n",
    "# Keep track of the diffuse curvatures, interpolated at barycenters in triangles of the surface mesh, and of the \n",
    "# areas of the triangles. The 2D surface mesh is extracted from the 3D volume u with marching cubes of skimage.\n",
    "Kap_vals = {}\n",
    "Areas = {}\n",
    "\n",
    "# Keep track of the normalized discrepancies.\n",
    "ratios = np.zeros(nb_shapes) # > .75 means non-viable shapes\n",
    "    \n",
    "def uniform_rand(a,b) : # a < b\n",
    "    return (b-a) * np.random.rand() + a\n",
    "\n",
    "for exp in range(nb_shapes) :\n",
    "    \n",
    "    one_viable_shape = False\n",
    "    \n",
    "    while not one_viable_shape :\n",
    "        \n",
    "        # random initialization for each shape\n",
    "        A0 = 40 * delta_x * np.random.rand(3,Z,X,Y)\n",
    "        A0 = torch.Tensor(A0).type(dtype)\n",
    "        a20 = 1\n",
    "        a11 = uniform_rand(-4,4)\n",
    "        a02 = uniform_rand(1/15,15)\n",
    "        b10 = uniform_rand(-200,200)\n",
    "        b01 = uniform_rand(-200,200)\n",
    "        c = uniform_rand(-3000,3000)\n",
    "        M0 = uniform_rand(-0.75, -0.15)\n",
    "\n",
    "        params = eps, a20, a11, a02, b10, b01, c\n",
    "\n",
    "        # write all the specifications in the meta file\n",
    "        print('Experiment {:04d}'.format(exp))\n",
    "        print('Parameters {} '.format(params))\n",
    "        file_object = open(niifolder + 'meta.txt', 'a')\n",
    "        file_object.write('Experiment = {:04d} \\n'.format(exp))\n",
    "        file_object.close()\n",
    "\n",
    "        # generate but without showing any figure\n",
    "        u, viable_OK = generate(A0, params, M0, delta_x, maxeval = MAXEVAL, snapshot_folder = niifolder, \n",
    "                        exp_title = '{:04d} '.format(exp), display_all = False, check_viable = True)\n",
    "        \n",
    "        if viable_OK :\n",
    "            one_viable_shape = True\n",
    "            \n",
    "        else : \n",
    "            file_object = open(niifolder + 'meta.txt', 'a')\n",
    "            file_object.write('This was a non-viable shape above. \\n \\n \\n')\n",
    "            file_object.close()\n",
    "        \n",
    "            # keep track of the NON viable parameters \n",
    "            file_object = open(niifolder + 'non_viable.txt', 'a') \n",
    "            str_tup = tuple([ formatted(x) for x in [a20, a11, a02, b10, b01, c, M0]])\n",
    "            file_object.write('{} {} {} {} {} {} {} \\n'.format(*str_tup))\n",
    "            file_object.close()\n",
    "        \n",
    "    # save the coeffs + mass used for the viable shapes\n",
    "    file_object = open(niifolder + 'coeffs_and_mass.txt', 'a') \n",
    "    str_tup = tuple([ formatted(x) for x in [a20, a11, a02, b10, b01, c, M0]])\n",
    "    file_object.write('{} {} {} {} {} {} {} \\n'.format(*str_tup))\n",
    "    file_object.close()\n",
    "\n",
    "    # save the normalized discrepancyies of the viable shapes\n",
    "    ratios[exp] = ratio_discr(u)\n",
    "    file_object = open(niifolder + 'normalized_discreps.txt', 'a')\n",
    "    file_object.write('{} \\n'.format(ratios[exp]))\n",
    "    file_object.close()\n",
    "    \n",
    "    # also write them in the meta file\n",
    "    file_object = open(niifolder + 'meta.txt', 'a')\n",
    "    file_object.write('discr = {} \\n \\n \\n'.format(ratios[exp])) # small error: should write ratio = ...\n",
    "    file_object.close()\n",
    "\n",
    "    # save viable u as .nii.gz\n",
    "    str_tup = tuple([ formatted(x) for x in [a20, a11, a02, b10, b01, c, M0]])\n",
    "    name = 'exp {:04d} coeffs [{} {} {} {} {} {}] m {}'.format(exp,*str_tup)\n",
    "    save_nii(np.floor(100 * u) / 100, niifolder + name) # gains space without loosing smoothness a\n",
    "    \n",
    "    # plot and save its curvature diagram\n",
    "    kap1_eps, kap2_eps = kap_eps(u)\n",
    "\n",
    "    kap1_vals, kap2_vals, areas = \\\n",
    "    curvhist(u, kap1_eps, kap2_eps, delta_x = 0.01, show_figs = False)\n",
    "\n",
    "    x,y = np.clip(kap1_vals, -100,100), np.clip(kap2_vals, -100, 100)\n",
    "    density_scatter(x,y, areas, showid = True, equalaxis = True, \n",
    "                    bins = 100, xlabel = 'kap1', ylabel = 'kap2', \n",
    "                    save = True, save_name = diagsfolder + name + ' kap1_kap2.png')\n",
    "    \n",
    "    # discard triangles of the mesh of nearly zero area\n",
    "    discard_indices = np.where(areas < 1e-4)[0]\n",
    "    areas = np.delete(areas, discard_indices, axis = 0)\n",
    "    kap1_vals = np.delete(kap1_vals, discard_indices, axis = 0)\n",
    "    kap2_vals = np.delete(kap2_vals, discard_indices, axis = 0)\n",
    "\n",
    "    Kap_vals[exp] = np.vstack((kap1_vals,kap2_vals)).T\n",
    "    Areas[exp] = areas\n",
    "\n",
    "    clear_output()\n",
    "    torch.cuda.empty_cache()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geomloss\n",
    "\n",
    "# This gives an approximation of the squared Wasserstein distance between 2 curvature diagrams assimilated \n",
    "# to weighted point clouds (positions: values of (kap1_eps, kap2_eps), weights: triangle areas of the mesh).\n",
    "\n",
    "# To speed up computations, for each comparison we only consider 10000 triangles randomly taken from the mesh.\n",
    "# Actually, this will no more be necessary once a new release of geomloss will be made!! (private communication)\n",
    "\n",
    "loss = geomloss.SamplesLoss('sinkhorn',\n",
    "                    p = 2, blur = 1, reach = 20) # squared distance!!!\n",
    "\n",
    "# Fill the distance matrix\n",
    "Dists = np.zeros((nb_shapes, nb_shapes))\n",
    "\n",
    "for i in range(nb_shapes) :\n",
    "    for j in range(nb_shapes) :\n",
    "        if j >= i + 1 : # only filling off-diagonal triangular sup\n",
    "\n",
    "            x_i = Kap_vals[i]\n",
    "            y_j = Kap_vals[j]\n",
    "            a_i = Areas[i]\n",
    "            b_j = Areas[j]\n",
    "\n",
    "            arr_i = np.arange(len(x_i))\n",
    "            arr_j = np.arange(len(y_j))\n",
    "            np.random.shuffle(arr_i)\n",
    "            np.random.shuffle(arr_j)\n",
    "            subsamp_i = arr_i[:10000] # only taking max. 10000 cells randomly taken from the mesh\n",
    "            subsamp_j = arr_j[:10000] # idem here. \n",
    "\n",
    "            x_i = x_i[subsamp_i]\n",
    "            a_i = a_i[subsamp_i]\n",
    "            y_j = y_j[subsamp_j]\n",
    "            b_j = b_j[subsamp_j]\n",
    "            \n",
    "            a_i /= a_i.sum()\n",
    "            b_j /= b_j.sum()\n",
    "            \n",
    "            x_i = torch.from_numpy(x_i).contiguous().type(dtype)\n",
    "            a_i = torch.from_numpy(a_i).type(dtype)\n",
    "            y_j = torch.from_numpy(y_j).contiguous().type(dtype)\n",
    "            b_j = torch.from_numpy(b_j).type(dtype)\n",
    "\n",
    "            Dists[i,j] = loss(a_i, x_i, b_j, y_j).abs().sqrt()\n",
    "\n",
    "            if j % 10 == 0 :\n",
    "                print('i,j = ', i, j)\n",
    "                print('dist = ', Dists[i,j])\n",
    "                \n",
    "            if j == nb_shapes - 1 : # completed i lines of the table! let's save in case it crashes...\n",
    "                np.save(niifolder + 'Dists_temp.npy', Dists[:i+1,:])\n",
    "        \n",
    "Dists = Dists + Dists.T # it was only triangular superior strict\n",
    "\n",
    "print(Dists)\n",
    "np.save(niifolder + 'Dists.npy', Dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now run UMAP with the precomputed distance matrix Dists\n",
    "\n",
    "RANDOM_SEED = 1 # as in my paper\n",
    "\n",
    "# in the paper, I took n_neighbors = 25, min_dist = 0.05 and spread = 1\n",
    "reducer = umap.UMAP(\n",
    "    n_neighbors = 25,       # default: 15\n",
    "    n_components = 2,       # 2D atlas\n",
    "    metric = 'precomputed', # we have already computed the pairwise distances\n",
    "    min_dist = .05,         # default: 0.1\n",
    "    spread = 1,             # default: 1\n",
    "    random_state = RANDOM_SEED)\n",
    "\n",
    "embedding = reducer.fit_transform(Dists) \n",
    "\n",
    "\n",
    "# Plot the UMAP atlas with dots colored by Hdbscan for visualization purpose\n",
    "\n",
    "scan_labels = SCAN_cluster(embedding)\n",
    "scatter_atlas(embedding, scan_labels, 'Atlas', folder = niifolder, size = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extension 1 - Include orientation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some folders to save the results\n",
    "\n",
    "niifolder = '../results/Orientation/'\n",
    "curvesfolder = niifolder + 'Curves/'\n",
    "diagsfolder = niifolder + 'Diagrams/'\n",
    "\n",
    "if not os.path.exists(niifolder):\n",
    "    print(niifolder + ' folder does not exist, creating it...')\n",
    "    os.makedirs(niifolder)\n",
    "if not os.path.exists(curvesfolder):\n",
    "    print('Curves subfolder does not exist, creating it...')\n",
    "    os.makedirs(curvesfolder)\n",
    "if not os.path.exists(diagsfolder):\n",
    "    print('Diagrams subfolder does not exist, creating it...')\n",
    "    os.makedirs(diagsfolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can add an orientation loss to the curvature energy.\n",
    "\n",
    "Z,X,Y = 100,100,100\n",
    "eps = 0.02\n",
    "delta_x = 1/100\n",
    "\n",
    "MAXEVAL = 8000\n",
    "\n",
    "# Specify a unit vector theta that defines a direction\n",
    "\n",
    "theta = np.array([1,0,0]) # direction of the Z axis (first axis in my convention)\n",
    "mu = 1000\n",
    "\n",
    "# tubes\n",
    "a20, a11, a02, b10, b01, c = 1,2,6,-40,-40,400\n",
    "M0 = -0.6\n",
    "\n",
    "params = eps, a20, a11, a02, b10, b01, c, mu, theta\n",
    "\n",
    "# random initialization\n",
    "A0 = 40 * delta_x * np.random.rand(3,Z,X,Y) # 20 or 40 * delta_x * ...\n",
    "A0 = torch.Tensor(A0).type(dtype)\n",
    "\n",
    "u = generate(A0, params, M0, delta_x, maxeval = MAXEVAL, snapshot_folder = niifolder, exp_title = 'orientation ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save u as .nii.gz\n",
    "str_tup = tuple([ formatted(x) for x in [a20, a11, a02, b10, b01, c, M0, mu]])\n",
    "name = 'orientation coeffs [{} {} {} {} {} {}] m {} mu {}'.format(*str_tup)\n",
    "save_nii(np.floor(100 * u) / 100, niifolder + name) # gains space without loosing smoothness a\n",
    "\n",
    "# plot and save its curvature diagram\n",
    "plot_curvature_diagram(u, save = True, save_name = diagsfolder + name + ' kap1_kap2.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extension 2 : Spatialized parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some folders to save the results\n",
    "\n",
    "niifolder = '../results/Spatialization/'\n",
    "curvesfolder = niifolder + 'Curves/'\n",
    "diagsfolder = niifolder + 'Diagrams/'\n",
    "\n",
    "if not os.path.exists(niifolder):\n",
    "    print(niifolder + ' folder does not exist, creating it...')\n",
    "    os.makedirs(niifolder)\n",
    "if not os.path.exists(curvesfolder):\n",
    "    print('Curves subfolder does not exist, creating it...')\n",
    "    os.makedirs(curvesfolder)\n",
    "if not os.path.exists(diagsfolder):\n",
    "    print('Diagrams subfolder does not exist, creating it...')\n",
    "    os.makedirs(diagsfolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now, the generation parameters themselves are spatially varying. We talk about \"spatialized parameters\".\n",
    "# Any of the coefficients, the mass, or even (mu, theta) and eps can be spatialized.\n",
    "# To do so, they have to be torch.tensors.\n",
    "\n",
    "# Here, I give the example of Fig 1. in my article,\n",
    "# where I make a 1D linear interpolation of 4 textures along one axis.\n",
    "# Note: I repeat the first and last textures because with periodic conditions it is \n",
    "# then easier to obtain \"pure\" textures at the extremities.\n",
    "\n",
    "# If you visualize the curvature diagrams, you will observe how the various reference textures can still \n",
    "# be seen, but they are superposed into a bigger hybrid diagram (not shown in the paper, so discover it!)\n",
    "\n",
    "Z,X,Y = 50, 100, 600\n",
    "delta_x = 1/100\n",
    "eps = 0.02\n",
    "\n",
    "x_vals = 50 + 100 * np.arange(-1,7) # 6 squares\n",
    "print(x_vals)\n",
    "\n",
    "from cvtub.utils import convert_params\n",
    "\n",
    "# layers\n",
    "h2,H0,k1,s,kap1_0,t,kap2_0 = 1,0,0,1,0,1,0\n",
    "a1 = convert_params(h2,H0,k1,s,kap1_0,t,kap2_0)\n",
    "m1 = -0.4\n",
    "\n",
    "# repeat the first texture (visualization)\n",
    "a0 = a1\n",
    "m0 = m1\n",
    "\n",
    "# tubes\n",
    "h2,H0,k1,s,kap1_0,t,kap2_0 = 1,20,0,0,0,5,0\n",
    "a2 = convert_params(h2,H0,k1,s,kap1_0,t,kap2_0)\n",
    "m2 = -0.6\n",
    "\n",
    "# spheres\n",
    "h2,H0,k1,s,kap1_0,t,kap2_0 = 1,25,0,1,12.5,1,12.5\n",
    "a3 = convert_params(h2,H0,k1,s,kap1_0,t,kap2_0)\n",
    "m3 = -0.7\n",
    "\n",
    "# trabec_2\n",
    "h2,H0,k1,s,kap1_0,t,kap2_0 = 1,45,0,1,45,10,0 #1,50,0,1,50,10,0 # \n",
    "a4 = convert_params(h2,H0,k1,s,kap1_0,t,kap2_0)\n",
    "m4 = -0.6\n",
    "\n",
    "# repeat the last texture (visualization)\n",
    "a5 = a4\n",
    "m5 = m4\n",
    "\n",
    "a0 = np.array(a0)\n",
    "a1 = np.array(a1)\n",
    "a2 = np.array(a2)\n",
    "a3 = np.array(a3)\n",
    "a4 = np.array(a4)\n",
    "a5 = np.array(a5)\n",
    "\n",
    "coeffs_vals = np.concatenate((a5[None], a0[None], a1[None], a2[None], a3[None], \n",
    "                              a4[None], a5[None], a0[None]), axis = 0)\n",
    "\n",
    "coeffs_vals = coeffs_vals.T # coeffs\n",
    "m_vals = np.array([m5,m0,m1,m2,m3,m4,m5,m0]) # masses\n",
    "\n",
    "# write the ref values\n",
    "file_object = open(niifolder + 'meta.txt', 'a')\n",
    "file_object.write('coeffs = \\n')\n",
    "file_object.write(str(coeffs_vals))\n",
    "file_object.write('masses = \\n')\n",
    "file_object.write(str(m_vals))\n",
    "file_object.write('\\n')\n",
    "file_object.close()\n",
    "\n",
    "# 1D interpolation with scipy\n",
    "import scipy\n",
    "f = scipy.interpolate.interp1d(x_vals, coeffs_vals, kind='linear', fill_value = 'extrapolate', axis= -1)\n",
    "g = scipy.interpolate.interp1d(x_vals, m_vals, kind='linear', fill_value = 'extrapolate', axis= -1)\n",
    "\n",
    "x_new = np.arange(Y)\n",
    "coeffs_new = f(x_new)\n",
    "m_new = g(x_new)\n",
    "print(coeffs_new.shape)\n",
    "\n",
    "a20, a11, a02, b10, b01, c = torch.tensor(coeffs_new).type(dtype)\n",
    "\n",
    "a20 = a20[None,None,:]\n",
    "a11 = a11[None,None,:]\n",
    "a02 = a02[None,None,:]\n",
    "b10 = b10[None,None,:]\n",
    "b01 = b01[None,None,:]\n",
    "c   =   c[None,None,:]\n",
    "\n",
    "M0  = torch.tensor(m_new).type(dtype)\n",
    "M0  = M0[None,None,:]\n",
    "\n",
    "# random initialization\n",
    "A0 = 40 * delta_x * np.random.rand(3,Z,X,Y)\n",
    "A0 = torch.Tensor(A0).type(dtype)\n",
    "\n",
    "# generate now!\n",
    "params = eps, a20, a11, a02, b10, b01, c\n",
    "\n",
    "u = generate(A0, params, M0, delta_x, maxeval = 10000, snapshot_folder = niifolder, exp_title = 'spatialized ')\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# save u as .nii.gz\n",
    "save_nii(u, niifolder + 'spatialized') # save original u\n",
    "\n",
    "# plot and save its curvature diagram\n",
    "plot_curvature_diagram(u, save = True, save_name = diagsfolder + name + ' kap1_kap2.png')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
