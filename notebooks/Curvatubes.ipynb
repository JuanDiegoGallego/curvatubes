{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use this script\n",
    "\n",
    "Run all the cells before Section \"Experiment 2\". From there, you can run one of the following experiments independently:\n",
    "\n",
    "- (**Exp 1** - Willmore validation : not here but in the other notebook)\n",
    "- **Exp 2** - Generates a single shape (and shows how to track the convergence)\n",
    "- **Exp 3** - Bilinear interpolation\n",
    "- **Exp 4** - Generate random shapes and plot them in UMAP\n",
    "\n",
    "The notebook also contains a few extensions:\n",
    "\n",
    "- **Ext 1** - Orientation\n",
    "- **Ext 2** - Spatialization\n",
    "\n",
    "For more details, please refer to my paper [here](https://arxiv.org/abs/2103.04856)!\n",
    "\n",
    "**If you find any problem in this script**, please contact me at a.song19@imperial.ac.uk.\n",
    "Good luck for generating beautiful shapes! If you get interesting shapes that have not been featured\n",
    "in the paper and want to show them to me, I will be happy to discuss about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import string\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "def formatted(f): return format(f, '.3f').rstrip('0').rstrip('.')\n",
    "\n",
    "import torch\n",
    "dtype = torch.cuda.FloatTensor # we work with GPUs # if torch.cuda.is_available() else torch.FloatTensor\n",
    "\n",
    "# curvatubes imports\n",
    "from cvtub.utils import slices, single, load_nii, save_nii, random_init, init_balls\n",
    "from cvtub.energy import discrepancy, ratio_discr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main generator function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function that generates 3D shapes with curvatubes\n",
    "\n",
    "# optimizer: Adam\n",
    "# flow type: conservative H^{-1}\n",
    "# periodic boundary conditions\n",
    "\n",
    "\n",
    "from cvtub.generator import _generate_shape\n",
    "\n",
    "def generate(A0, params, M0, delta_x, maxeval = 10000, snapshot_folder = '', exp_title = '',\n",
    "             display_all = True, check_viable = False, cond_take_snapshot = None) :  \n",
    "    \n",
    "    '''Optimizes the phase-field Feps(u) ( see paper / see comments in cvtub/energy.py ) '''\n",
    "    \n",
    "    xi =  1e-6\n",
    "    flow_type = 'cons'\n",
    "    mode = 'periodic'\n",
    "    optim_method = 'adam'\n",
    "    sigma_blur = 2\n",
    "    Z,X,Y = A0[0].shape\n",
    "\n",
    "    optim_props = {'maxeval': maxeval, 'sigma_blur': sigma_blur, 'lr': .001, 'eps_adam' : 1e-2, \n",
    "                   'betas' : (0.9,0.999), 'weight_decay' : 0, 'amsgrad' : False,\n",
    "                   'display_it_nb' : 1000, 'fill_curve_nb' : 50}\n",
    "    \n",
    "    u = _generate_shape(A0, params, delta_x, xi, optim_method, optim_props, flow_type, mode,\n",
    "                               M0 = M0, snapshot_folder = snapshot_folder, exp_title = exp_title, \n",
    "                                cond_take_snapshot = cond_take_snapshot, display_all = display_all, \n",
    "                                check_viable = check_viable)\n",
    "    \n",
    "    if check_viable == True :\n",
    "        u, viable_bool = u\n",
    "        return u.detach().cpu().numpy(), viable_bool\n",
    "\n",
    "    return u.detach().cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function which plots the curvature diagram of a shape \n",
    "# defined as the zero level set of a phase-field u\n",
    "\n",
    "from cvtub.curvdiags import kap_eps, curvhist, density_scatter\n",
    "\n",
    "def plot_curvature_diagram(u, save = True, save_name = 'curvature_diagram.png'):\n",
    "\n",
    "    kap1_eps, kap2_eps = kap_eps(u)\n",
    "\n",
    "    kap1_vals, kap2_vals, areas = \\\n",
    "    curvhist(u, kap1_eps, kap2_eps, delta_x = 0.01, show_figs = False)\n",
    "\n",
    "    x,y = np.clip(kap1_vals, -100,100), np.clip(kap2_vals, -100, 100)\n",
    "    density_scatter(x,y, areas, showid = True, equalaxis = True, \n",
    "                    bins = 100, xlabel = 'kap1', \n",
    "                    ylabel = 'kap2', save = save, save_name = save_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can stop here, and then run individual experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2 - Generate a single shape\n",
    "\n",
    "**Generate** shapes with `generate()`.\n",
    "\n",
    "We work with a vector field A instead of the scalar field u itself, because the $H^{-1}$ flow in u\n",
    "translates into a $L^2$ flow in A (see the paper). The main parameters are\n",
    "\n",
    "- ```params = eps, a20, a11, a02, b10, b01, c```, where\n",
    "    - `eps` is the **phase-transition parameter**\n",
    "    - `a20, a11, a02, b10, b01, c` are the **polynomial coefficients** in the curvature functional\n",
    "\n",
    "\n",
    "- the **mass** `M0`, which is the imposed average of the phase-field *u*\n",
    "- `MAXEVAL`, the nb of iterations of the algorithm. In the paper, I chose 8000 to be very secure, but you can actually take 4000 (sufficient) or even 1000 (approximate shape).\n",
    "\n",
    "> *Remarks*:\n",
    "> - in the paper, the term \"generation parameters\" refers to the tuple `(a20, a11, a02, b10, b01, c, M0)`\n",
    "> -  to include orientation, or use spatialized parameters, see **Ext 1** and **Ext 2**.\n",
    "\n",
    "**Visualize its curvature diagram** with `plot_curvature_diagram()`.\n",
    "\n",
    "You can plot the curvature diagrams, i.e., the histograms of the diffuse principal curvatures `(kap1_eps, kap2_eps)`.\n",
    "\n",
    "**Export the phase-field $u$** into `.nii.gz` format with `save_nii()`.\n",
    "\n",
    "You can then visualize the level set $\\{u = 0\\}$ for instance in Paraview or 3DSlicer.\\\n",
    "You can also visualize $u$ or $\\{u = 0\\}$ in the notebook itself using [pyvista](https://docs.pyvista.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some folders to save the results\n",
    "\n",
    "niifolder = '../results/Experiment_2/'\n",
    "curvesfolder = niifolder + 'Curves/'\n",
    "diagsfolder = niifolder + 'Diagrams/'\n",
    "\n",
    "if not os.path.exists(niifolder):\n",
    "    print(niifolder + ' folder does not exist, creating it...')\n",
    "    os.makedirs(niifolder)\n",
    "if not os.path.exists(curvesfolder):\n",
    "    print('Curves subfolder does not exist, creating it...')\n",
    "    os.makedirs(curvesfolder)\n",
    "if not os.path.exists(diagsfolder):\n",
    "    print('Diagrams subfolder does not exist, creating it...')\n",
    "    os.makedirs(diagsfolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Number of iterations?\n",
    "MAXEVAL = 4000 \n",
    "# 4000 are generally sufficient, 8000 are over-sufficient\n",
    "\n",
    "# Sizes\n",
    "Z,X,Y = 100,100,100\n",
    "delta_x = 1/100\n",
    "\n",
    "# Initialize A = A0: a random vector field with values in R^3\n",
    "A0 = 40 * delta_x * np.random.rand(3,Z,X,Y)\n",
    "A0 = torch.Tensor(A0).type(dtype)\n",
    "slices(A0[0]) # show three 2D slices of the 3D scalar field A0[0] \n",
    "\n",
    "# Parameters\n",
    "eps = 0.02\n",
    "a20, a11, a02, b10, b01, c = 1, 0.85, 6, -80, -7.5, 1770\n",
    "M0 = -0.42\n",
    "params = eps, a20, a11, a02, b10, b01, c\n",
    "\n",
    "# Generate the shape - you will see slices of u along the iterations, and the loss curves are saved in their folder\n",
    "u = generate(A0, params, M0, delta_x, maxeval = MAXEVAL, snapshot_folder = niifolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save u as a .nii.gz file\n",
    "str_tup = tuple([ formatted(x) for x in [eps, a20, a11, a02, b10, b01, c, M0]])\n",
    "name = 'eps {} coeffs [{}, {}, {}, {}, {}, {}] m {}'.format(*str_tup)\n",
    "print(name)\n",
    "save_nii(np.floor(100 * u) / 100, niifolder + name) # or u if you have more space\n",
    "\n",
    "# Plot and save its curvature diagram\n",
    "plot_curvature_diagram(u, save = True, save_name = diagsfolder + name + ' kap1_kap2.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to keep track of the convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define at which iterations you want to save the current u as a .nii.gz file\n",
    "\n",
    "def cond_take_snapshot(iteration):\n",
    "    if iteration in [10, 100, 200, 400, 1000, 2000, 4000] :\n",
    "        return True\n",
    "\n",
    "u, A = generate(A0, params, M0, delta_x, maxeval = 4001, snapshot_folder = niifolder, cond_take_snapshot = cond_take_snapshot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 3 - Bilinear interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some folders to save the results\n",
    "\n",
    "niifolder = '../results/Experiment_3/'\n",
    "curvesfolder = niifolder + 'Curves/'\n",
    "diagsfolder = niifolder + 'Diagrams/'\n",
    "\n",
    "if not os.path.exists(niifolder):\n",
    "    print(niifolder + ' folder does not exist, creating it...')\n",
    "    os.makedirs(niifolder)\n",
    "if not os.path.exists(curvesfolder):\n",
    "    print('Curves subfolder does not exist, creating it...')\n",
    "    os.makedirs(curvesfolder)\n",
    "if not os.path.exists(diagsfolder):\n",
    "    print('Diagrams subfolder does not exist, creating it...')\n",
    "    os.makedirs(diagsfolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bilinear interpolation between the generation parameters of\n",
    "# 4 ref shape textures: layers, spheres, tubes, sponges\n",
    "# All simulations start from the same A0\n",
    "\n",
    "from cvtub.utils import convert_params\n",
    "    \n",
    "# nb of iterations in the algorithm\n",
    "MAXEVAL = 4000 # 8000 in the paper\n",
    "\n",
    "# sizes\n",
    "Z,X,Y = 100,100,100\n",
    "eps = 0.02\n",
    "delta_x = 1/100\n",
    "\n",
    "# layers\n",
    "M0 = -0.3\n",
    "h2,H0,k1,s,kap1_0,t,kap2_0 = 1,0,0,1,0,1,0\n",
    "a20, a11, a02, b10, b01, c = convert_params(h2,H0,k1,s,kap1_0,t,kap2_0)\n",
    "pm_layers = eps, a20, a11, a02, b10, b01, c, M0\n",
    "\n",
    "# spheres\n",
    "M0 = -0.6\n",
    "R = 0.08\n",
    "h2,H0,k1,s,kap1_0,t,kap2_0 = 1,2/R,0,1,1/R,1,1/R\n",
    "a20, a11, a02, b10, b01, c = convert_params(h2,H0,k1,s,kap1_0,t,kap2_0)\n",
    "pm_spheres = eps, a20, a11, a02, b10, b01, c, M0\n",
    "\n",
    "# tubes\n",
    "M0 = -0.7\n",
    "r = 0.04\n",
    "h2,H0,k1,s,kap1_0,t,kap2_0 = 1,1/r,0,1,1/r,10,0\n",
    "a20, a11, a02, b10, b01, c = convert_params(h2,H0,k1,s,kap1_0,t,kap2_0)\n",
    "pm_tubes = eps, a20, a11, a02, b10, b01, c, M0\n",
    "\n",
    "# sponges\n",
    "M0 = -0.25\n",
    "h2,H0,k1,s,kap1_0,t,kap2_0 = 1,5,0.8,0,0,1,0\n",
    "a20, a11, a02, b10, b01, c = convert_params(h2,H0,k1,s,kap1_0,t,kap2_0)\n",
    "pm_sponges = eps, a20, a11, a02, b10, b01, c, M0\n",
    "\n",
    "surnames = ['layers','spheres','tubes','sponges']\n",
    "pms = [pm_layers, pm_spheres, pm_tubes, pm_sponges]\n",
    "\n",
    "for i in range(4) :\n",
    "    print(surnames[i])\n",
    "    print(pms[i])\n",
    "    \n",
    "x1, x2 = 0, 1\n",
    "y1, y2 = 0, 1\n",
    "\n",
    "n = 4 # nb of intervals between endpoints (n = 4 in the paper)\n",
    "\n",
    "q11 = np.array(pm_layers)[None,None,:]\n",
    "q12 = np.array(pm_spheres)[None,None,:]\n",
    "q22 = np.array(pm_tubes)[None,None,:]\n",
    "q21 = np.array(pm_sponges)[None,None,:]\n",
    "\n",
    "x,y = np.mgrid[0:1:(n+1)*1j, 0:1:(n+1)*1j] # is,js convention\n",
    "x = x[:,:,None] \n",
    "y = y[:,:,None]\n",
    "\n",
    "# bilinear interpolation of the parameters (eps, [coeffs], M0)\n",
    "pms_interp = ( q11 * (x2 - x) * (y2 - y) + q21 * (x - x1) * (y2 - y) + q12 * (x2 - x) * (y - y1) + q22 * (x - x1) * (y - y1) ) / ((x2 - x1) * (y2 - y1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize A0 (the same for all)\n",
    "\n",
    "A0 = 40 * delta_x * np.random.rand(3,Z,X,Y) # 20 or 40 * delta_x * ...\n",
    "A0 = torch.Tensor(A0).type(dtype)\n",
    "\n",
    "# Generate bilinear interpolation now!\n",
    "\n",
    "for i in range(n+1) :\n",
    "    for j in range(n+1) :\n",
    "        \n",
    "        # Specify and save parameter values\n",
    "        params = pms_interp[i,j,:-1]\n",
    "        M0 = pms_interp[i,j,-1]\n",
    "        a20, a11, a02, b10, b01, c = params[1:7]\n",
    "        \n",
    "        print('I,J = {},{}'.format(i,j))\n",
    "        print('Coeffs {} '.format(params[1:7]))\n",
    "        print('Mass {} '.format(M0))\n",
    "\n",
    "        file_object = open(niifolder + 'meta.txt', 'a')\n",
    "        file_object.write('I,J = {},{} \\n'.format(i,j))\n",
    "        file_object.write('eps {} \\n'.format(eps))\n",
    "        file_object.close()\n",
    "\n",
    "        u = generate(A0, params, M0, delta_x, maxeval = MAXEVAL, snapshot_folder = niifolder, exp_title = 'I {} J {} '.format(i,j))\n",
    "\n",
    "        str_tup = tuple([ formatted(x) for x in [a20, a11, a02, b10, b01, c, M0]])\n",
    "        name = 'I {} J {} coeffs [{} {} {} {} {} {}] m {}'.format(i,j,*str_tup)\n",
    "        print(name)\n",
    "        \n",
    "        # Save u as a .nii.gz file\n",
    "        save_nii(np.floor(100 * u) / 100, niifolder + name) # or u, if you have more space\n",
    "\n",
    "        # Plot and save its curvature diagram\n",
    "        plot_curvature_diagram(u, save = True, save_name = diagsfolder + name + ' kap1_kap2.png')\n",
    "\n",
    "        clear_output()\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 4 - Generate random shapes and plot them in UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some folders to save the results\n",
    "\n",
    "niifolder = '../results/Experiment_4/'\n",
    "curvesfolder = niifolder + 'Curves/'\n",
    "diagsfolder = niifolder + 'Diagrams/'\n",
    "\n",
    "if not os.path.exists(niifolder):\n",
    "    print(niifolder + ' folder does not exist, creating it...')\n",
    "    os.makedirs(niifolder)\n",
    "if not os.path.exists(curvesfolder):\n",
    "    print('Curves subfolder does not exist, creating it...')\n",
    "    os.makedirs(curvesfolder)\n",
    "if not os.path.exists(diagsfolder):\n",
    "    print('Diagrams subfolder does not exist, creating it...')\n",
    "    os.makedirs(diagsfolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some functions to visualize the final plot...\n",
    "\n",
    "import umap\n",
    "import hdbscan\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "def give_color_array(nb_clusters) : \n",
    "    # gives a collection of colors to make nice legends\n",
    "    colors1 = plt.cm.tab20b(np.linspace(0., 1, 128))\n",
    "    colors2 = plt.cm.tab20c(np.linspace(0, 1, 128))\n",
    "    colors = np.vstack((colors1, colors2))\n",
    "    mymap = mcolors.LinearSegmentedColormap.from_list('my_colormap', colors)\n",
    "    cm = plt.get_cmap(mymap)\n",
    "    colors = [cm(1.*i/nb_clusters) for i in range(nb_clusters)]\n",
    "    return colors\n",
    "\n",
    "def SCAN_cluster(umap_embedding) : # shape (nb of points, dimension) \n",
    "    clustering = hdbscan.HDBSCAN(\n",
    "        min_samples = 10,\n",
    "        min_cluster_size = 10)\n",
    "    labels = clustering.fit_predict(umap_embedding)\n",
    "    return labels\n",
    "\n",
    "def scatter_atlas(points, labels, title_string = '', save = True, folder = '', \n",
    "                        size = 3, markerscale = 5) :\n",
    "    L = len(points)\n",
    "    unique_labels = np.unique(labels) # labels included between 0 and L-1\n",
    "    colors = give_color_array(len(unique_labels))\n",
    "        \n",
    "    plt.figure(figsize=(12,12))\n",
    "    ax = plt.gca()    \n",
    "\n",
    "    for i,l in enumerate(unique_labels) :\n",
    "        wh = np.where(labels == l)[0]\n",
    "        col = np.repeat(np.array(colors[i])[None], len(wh), axis = 0)\n",
    "        ax.scatter(points[wh,0], points[wh,1], s=size, c= col, label = l, edgecolors='none')\n",
    "\n",
    "    ax.set_title(title_string, fontsize=20)\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "    box = ax.get_position()\n",
    "    ax.set_position([box.x0, box.y0, box.width * 0.75, box.height]) # 0.75 good for 30 labels\n",
    "    ax.legend(loc='center left', bbox_to_anchor=(1, 0.5), markerscale = markerscale, prop = {'size':10})\n",
    "    if save :\n",
    "        plt.savefig(folder + title_string + '.png', dpi=200)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We generate random shapes by choosing random coefficients and only keeping viable shapes.\n",
    "# The pairwise Wasserstein distances are computed between all pairs of shapes with geomloss \n",
    "#                            https://www.kernel-operations.io/geomloss/\n",
    "# and UMAP embeds the dataset into a 2D atlas of shape textures.\n",
    "#                            https://umap-learn.readthedocs.io/en/latest/\n",
    "\n",
    "\n",
    "MAXEVAL = 8000 # 8000 in the paper.\n",
    "nb_shapes = 10 # nb_shapes = 1000 in the paper\n",
    "# P.S.: add some more zeros if you want to spend 3 days in it :) \n",
    "\n",
    "# Sizes\n",
    "Z,X,Y = 100,100,100\n",
    "delta_x = 1/100\n",
    "eps = 0.02\n",
    "\n",
    "# Keep track of the diffuse curvatures, interpolated at barycenters in triangles of the surface mesh, and of the \n",
    "# areas of the triangles. The 2D surface mesh is extracted from the 3D volume u with marching cubes of skimage.\n",
    "Kap_vals = {}\n",
    "Areas = {}\n",
    "\n",
    "# Keep track of the normalized discrepancies.\n",
    "ratios = np.zeros(nb_shapes) # > .75 means non-viable shapes\n",
    "    \n",
    "def uniform_rand(a,b) : # a < b\n",
    "    return (b-a) * np.random.rand() + a\n",
    "\n",
    "for exp in range(nb_shapes) :\n",
    "    \n",
    "    one_viable_shape = False\n",
    "    \n",
    "    while not one_viable_shape :\n",
    "        \n",
    "        # random initialization for each shape\n",
    "        A0 = 40 * delta_x * np.random.rand(3,Z,X,Y)\n",
    "        A0 = torch.Tensor(A0).type(dtype)\n",
    "        a20 = 1\n",
    "        a11 = uniform_rand(-4,4)\n",
    "        a02 = uniform_rand(1/15,15)\n",
    "        b10 = uniform_rand(-200,200)\n",
    "        b01 = uniform_rand(-200,200)\n",
    "        c = uniform_rand(-3000,3000)\n",
    "        M0 = uniform_rand(-0.75, -0.15)\n",
    "\n",
    "        params = eps, a20, a11, a02, b10, b01, c\n",
    "\n",
    "        # write all the specifications in the meta file\n",
    "        print('Experiment {:04d}'.format(exp))\n",
    "        print('Parameters {} '.format(params))\n",
    "        file_object = open(niifolder + 'meta.txt', 'a')\n",
    "        file_object.write('Experiment = {:04d} \\n'.format(exp))\n",
    "        file_object.close()\n",
    "\n",
    "        # generate but without showing any figure\n",
    "        u, viable_OK = generate(A0, params, M0, delta_x, maxeval = MAXEVAL, snapshot_folder = niifolder, \n",
    "                        exp_title = '{:04d} '.format(exp), display_all = False, check_viable = True)\n",
    "        \n",
    "        if viable_OK :\n",
    "            one_viable_shape = True\n",
    "            \n",
    "        else : \n",
    "            file_object = open(niifolder + 'meta.txt', 'a')\n",
    "            file_object.write('This was a non-viable shape above. \\n \\n \\n')\n",
    "            file_object.close()\n",
    "        \n",
    "            # keep track of the NON viable parameters \n",
    "            file_object = open(niifolder + 'non_viable.txt', 'a') \n",
    "            str_tup = tuple([ formatted(x) for x in [a20, a11, a02, b10, b01, c, M0]])\n",
    "            file_object.write('{} {} {} {} {} {} {} \\n'.format(*str_tup))\n",
    "            file_object.close()\n",
    "        \n",
    "    # save the coeffs + mass used for the viable shapes\n",
    "    file_object = open(niifolder + 'coeffs_and_mass.txt', 'a') \n",
    "    str_tup = tuple([ formatted(x) for x in [a20, a11, a02, b10, b01, c, M0]])\n",
    "    file_object.write('{} {} {} {} {} {} {} \\n'.format(*str_tup))\n",
    "    file_object.close()\n",
    "\n",
    "    # save the normalized discrepancyies of the viable shapes\n",
    "    ratios[exp] = ratio_discr(u)\n",
    "    file_object = open(niifolder + 'normalized_discreps.txt', 'a')\n",
    "    file_object.write('{} \\n'.format(ratios[exp]))\n",
    "    file_object.close()\n",
    "    \n",
    "    # also write them in the meta file\n",
    "    file_object = open(niifolder + 'meta.txt', 'a')\n",
    "    file_object.write('discr = {} \\n \\n \\n'.format(ratios[exp])) # small error: should write ratio = ...\n",
    "    file_object.close()\n",
    "\n",
    "    # save viable u as .nii.gz\n",
    "    str_tup = tuple([ formatted(x) for x in [a20, a11, a02, b10, b01, c, M0]])\n",
    "    name = 'exp {:04d} coeffs [{} {} {} {} {} {}] m {}'.format(exp,*str_tup)\n",
    "    save_nii(np.floor(100 * u) / 100, niifolder + name) # gains space without loosing smoothness a\n",
    "    \n",
    "    # plot and save its curvature diagram\n",
    "    kap1_eps, kap2_eps = kap_eps(u)\n",
    "\n",
    "    kap1_vals, kap2_vals, areas = \\\n",
    "    curvhist(u, kap1_eps, kap2_eps, delta_x = 0.01, show_figs = False)\n",
    "\n",
    "    x,y = np.clip(kap1_vals, -100,100), np.clip(kap2_vals, -100, 100)\n",
    "    density_scatter(x,y, areas, showid = True, equalaxis = True, \n",
    "                    bins = 100, xlabel = 'kap1', ylabel = 'kap2', \n",
    "                    save = True, save_name = diagsfolder + name + ' kap1_kap2.png')\n",
    "    \n",
    "    # discard triangles of the mesh of nearly zero area\n",
    "    discard_indices = np.where(areas < 1e-4)[0]\n",
    "    areas = np.delete(areas, discard_indices, axis = 0)\n",
    "    kap1_vals = np.delete(kap1_vals, discard_indices, axis = 0)\n",
    "    kap2_vals = np.delete(kap2_vals, discard_indices, axis = 0)\n",
    "\n",
    "    Kap_vals[exp] = np.vstack((kap1_vals,kap2_vals)).T\n",
    "    Areas[exp] = areas\n",
    "\n",
    "    clear_output()\n",
    "    torch.cuda.empty_cache()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geomloss\n",
    "\n",
    "# This gives an approximation of the squared Wasserstein distance between 2 curvature diagrams assimilated \n",
    "# to weighted point clouds (positions: values of (kap1_eps, kap2_eps), weights: triangle areas of the mesh).\n",
    "\n",
    "# To speed up computations, for each comparison we only consider 10000 triangles randomly taken from the mesh.\n",
    "# Actually, this will no more be necessary once a new release of geomloss will be made!! (private communication)\n",
    "\n",
    "loss = geomloss.SamplesLoss('sinkhorn',\n",
    "                    p = 2, blur = 1, reach = 20) # squared distance!!!\n",
    "\n",
    "# Fill the distance matrix\n",
    "Dists = np.zeros((nb_shapes, nb_shapes))\n",
    "\n",
    "for i in range(nb_shapes) :\n",
    "    for j in range(nb_shapes) :\n",
    "        if j >= i + 1 : # only filling off-diagonal triangular sup\n",
    "\n",
    "            x_i = Kap_vals[i]\n",
    "            y_j = Kap_vals[j]\n",
    "            a_i = Areas[i]\n",
    "            b_j = Areas[j]\n",
    "\n",
    "            arr_i = np.arange(len(x_i))\n",
    "            arr_j = np.arange(len(y_j))\n",
    "            np.random.shuffle(arr_i)\n",
    "            np.random.shuffle(arr_j)\n",
    "            subsamp_i = arr_i[:10000] # only taking max. 10000 cells randomly taken from the mesh\n",
    "            subsamp_j = arr_j[:10000] # idem here. \n",
    "\n",
    "            x_i = x_i[subsamp_i]\n",
    "            a_i = a_i[subsamp_i]\n",
    "            y_j = y_j[subsamp_j]\n",
    "            b_j = b_j[subsamp_j]\n",
    "            \n",
    "            a_i /= a_i.sum()\n",
    "            b_j /= b_j.sum()\n",
    "            \n",
    "            x_i = torch.from_numpy(x_i).contiguous().type(dtype)\n",
    "            a_i = torch.from_numpy(a_i).type(dtype)\n",
    "            y_j = torch.from_numpy(y_j).contiguous().type(dtype)\n",
    "            b_j = torch.from_numpy(b_j).type(dtype)\n",
    "\n",
    "            Dists[i,j] = loss(a_i, x_i, b_j, y_j).abs().sqrt()\n",
    "\n",
    "            if j % 10 == 0 :\n",
    "                print('i,j = ', i, j)\n",
    "                print('dist = ', Dists[i,j])\n",
    "                \n",
    "            if j == nb_shapes - 1 : # completed i lines of the table! let's save in case it crashes...\n",
    "                np.save(niifolder + 'Dists_temp.npy', Dists[:i+1,:])\n",
    "        \n",
    "Dists = Dists + Dists.T # it was only triangular superior strict\n",
    "\n",
    "print(Dists)\n",
    "np.save(niifolder + 'Dists.npy', Dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now run UMAP with the precomputed distance matrix Dists\n",
    "\n",
    "RANDOM_SEED = 1 # as in my paper\n",
    "\n",
    "# in the paper, I took n_neighbors = 25, min_dist = 0.05 and spread = 1\n",
    "reducer = umap.UMAP(\n",
    "    n_neighbors = 25,       # default: 15\n",
    "    n_components = 2,       # 2D atlas\n",
    "    metric = 'precomputed', # we have already computed the pairwise distances\n",
    "    min_dist = .05,         # default: 0.1\n",
    "    spread = 1,             # default: 1\n",
    "    random_state = RANDOM_SEED)\n",
    "\n",
    "embedding = reducer.fit_transform(Dists) \n",
    "\n",
    "\n",
    "# Plot the UMAP atlas with dots colored by Hdbscan for visualization purpose\n",
    "\n",
    "scan_labels = SCAN_cluster(embedding)\n",
    "scatter_atlas(embedding, scan_labels, 'Atlas', folder = niifolder, size = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extension 1 - Include orientation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some folders to save the results\n",
    "\n",
    "niifolder = '../results/Orientation/'\n",
    "curvesfolder = niifolder + 'Curves/'\n",
    "diagsfolder = niifolder + 'Diagrams/'\n",
    "\n",
    "if not os.path.exists(niifolder):\n",
    "    print(niifolder + ' folder does not exist, creating it...')\n",
    "    os.makedirs(niifolder)\n",
    "if not os.path.exists(curvesfolder):\n",
    "    print('Curves subfolder does not exist, creating it...')\n",
    "    os.makedirs(curvesfolder)\n",
    "if not os.path.exists(diagsfolder):\n",
    "    print('Diagrams subfolder does not exist, creating it...')\n",
    "    os.makedirs(diagsfolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can add an orientation loss to the curvature energy.\n",
    "\n",
    "Z,X,Y = 100,100,100\n",
    "eps = 0.02\n",
    "delta_x = 1/100\n",
    "\n",
    "MAXEVAL = 8000\n",
    "\n",
    "# Specify a unit vector theta that defines a direction\n",
    "\n",
    "theta = np.array([1,0,0]) # direction of the Z axis (first axis in my convention)\n",
    "mu = 1000\n",
    "\n",
    "# tubes\n",
    "a20, a11, a02, b10, b01, c = 1,2,6,-40,-40,400\n",
    "M0 = -0.6\n",
    "\n",
    "params = eps, a20, a11, a02, b10, b01, c, mu, theta\n",
    "\n",
    "# random initialization\n",
    "A0 = 40 * delta_x * np.random.rand(3,Z,X,Y) # 20 or 40 * delta_x * ...\n",
    "A0 = torch.Tensor(A0).type(dtype)\n",
    "\n",
    "u = generate(A0, params, M0, delta_x, maxeval = MAXEVAL, snapshot_folder = niifolder, exp_title = 'orientation ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save u as .nii.gz\n",
    "str_tup = tuple([ formatted(x) for x in [a20, a11, a02, b10, b01, c, M0, mu]])\n",
    "name = 'orientation coeffs [{} {} {} {} {} {}] m {} mu {}'.format(*str_tup)\n",
    "save_nii(np.floor(100 * u) / 100, niifolder + name) # gains space without loosing smoothness a\n",
    "\n",
    "# plot and save its curvature diagram\n",
    "plot_curvature_diagram(u, save = True, save_name = diagsfolder + name + ' kap1_kap2.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extension 2 : Spatialized parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some folders to save the results\n",
    "\n",
    "niifolder = '../results/Spatialization/'\n",
    "curvesfolder = niifolder + 'Curves/'\n",
    "diagsfolder = niifolder + 'Diagrams/'\n",
    "\n",
    "if not os.path.exists(niifolder):\n",
    "    print(niifolder + ' folder does not exist, creating it...')\n",
    "    os.makedirs(niifolder)\n",
    "if not os.path.exists(curvesfolder):\n",
    "    print('Curves subfolder does not exist, creating it...')\n",
    "    os.makedirs(curvesfolder)\n",
    "if not os.path.exists(diagsfolder):\n",
    "    print('Diagrams subfolder does not exist, creating it...')\n",
    "    os.makedirs(diagsfolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now, the generation parameters themselves are spatially varying. We talk about \"spatialized parameters\".\n",
    "# Any of the coefficients, the mass, or even (mu, theta) and eps can be spatialized.\n",
    "# To do so, they have to be torch.tensors.\n",
    "\n",
    "# Here, I give the example of Fig 1. in my article,\n",
    "# where I make a 1D linear interpolation of 4 textures along one axis.\n",
    "# Note: I repeat the first and last textures because with periodic conditions it is \n",
    "# then easier to obtain \"pure\" textures at the extremities.\n",
    "\n",
    "# If you visualize the curvature diagrams, you will observe how the various reference textures can still \n",
    "# be seen, but they are superposed into a bigger hybrid diagram (not shown in the paper, so discover it!)\n",
    "\n",
    "Z,X,Y = 50, 100, 600\n",
    "delta_x = 1/100\n",
    "eps = 0.02\n",
    "\n",
    "x_vals = 50 + 100 * np.arange(-1,7) # 6 squares\n",
    "print(x_vals)\n",
    "\n",
    "from cvtub.utils import convert_params\n",
    "\n",
    "# layers\n",
    "h2,H0,k1,s,kap1_0,t,kap2_0 = 1,0,0,1,0,1,0\n",
    "a1 = convert_params(h2,H0,k1,s,kap1_0,t,kap2_0)\n",
    "m1 = -0.4\n",
    "\n",
    "# repeat the first texture (visualization)\n",
    "a0 = a1\n",
    "m0 = m1\n",
    "\n",
    "# tubes\n",
    "h2,H0,k1,s,kap1_0,t,kap2_0 = 1,20,0,0,0,5,0\n",
    "a2 = convert_params(h2,H0,k1,s,kap1_0,t,kap2_0)\n",
    "m2 = -0.6\n",
    "\n",
    "# spheres\n",
    "h2,H0,k1,s,kap1_0,t,kap2_0 = 1,25,0,1,12.5,1,12.5\n",
    "a3 = convert_params(h2,H0,k1,s,kap1_0,t,kap2_0)\n",
    "m3 = -0.7\n",
    "\n",
    "# trabec_2\n",
    "h2,H0,k1,s,kap1_0,t,kap2_0 = 1,45,0,1,45,10,0 #1,50,0,1,50,10,0 # \n",
    "a4 = convert_params(h2,H0,k1,s,kap1_0,t,kap2_0)\n",
    "m4 = -0.6\n",
    "\n",
    "# repeat the last texture (visualization)\n",
    "a5 = a4\n",
    "m5 = m4\n",
    "\n",
    "a0 = np.array(a0)\n",
    "a1 = np.array(a1)\n",
    "a2 = np.array(a2)\n",
    "a3 = np.array(a3)\n",
    "a4 = np.array(a4)\n",
    "a5 = np.array(a5)\n",
    "\n",
    "coeffs_vals = np.concatenate((a5[None], a0[None], a1[None], a2[None], a3[None], \n",
    "                              a4[None], a5[None], a0[None]), axis = 0)\n",
    "\n",
    "coeffs_vals = coeffs_vals.T # coeffs\n",
    "m_vals = np.array([m5,m0,m1,m2,m3,m4,m5,m0]) # masses\n",
    "\n",
    "# write the ref values\n",
    "file_object = open(niifolder + 'meta.txt', 'a')\n",
    "file_object.write('coeffs = \\n')\n",
    "file_object.write(str(coeffs_vals))\n",
    "file_object.write('masses = \\n')\n",
    "file_object.write(str(m_vals))\n",
    "file_object.write('\\n')\n",
    "file_object.close()\n",
    "\n",
    "# 1D interpolation with scipy\n",
    "import scipy\n",
    "f = scipy.interpolate.interp1d(x_vals, coeffs_vals, kind='linear', fill_value = 'extrapolate', axis= -1)\n",
    "g = scipy.interpolate.interp1d(x_vals, m_vals, kind='linear', fill_value = 'extrapolate', axis= -1)\n",
    "\n",
    "x_new = np.arange(Y)\n",
    "coeffs_new = f(x_new)\n",
    "m_new = g(x_new)\n",
    "print(coeffs_new.shape)\n",
    "\n",
    "a20, a11, a02, b10, b01, c = torch.tensor(coeffs_new).type(dtype)\n",
    "\n",
    "a20 = a20[None,None,:]\n",
    "a11 = a11[None,None,:]\n",
    "a02 = a02[None,None,:]\n",
    "b10 = b10[None,None,:]\n",
    "b01 = b01[None,None,:]\n",
    "c   =   c[None,None,:]\n",
    "\n",
    "M0  = torch.tensor(m_new).type(dtype)\n",
    "M0  = M0[None,None,:]\n",
    "\n",
    "# random initialization\n",
    "A0 = 40 * delta_x * np.random.rand(3,Z,X,Y)\n",
    "A0 = torch.Tensor(A0).type(dtype)\n",
    "\n",
    "# generate now!\n",
    "params = eps, a20, a11, a02, b10, b01, c\n",
    "\n",
    "u = generate(A0, params, M0, delta_x, maxeval = 10000, snapshot_folder = niifolder, exp_title = 'spatialized ')\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# save u as .nii.gz\n",
    "save_nii(u, niifolder + 'spatialized') # save original u\n",
    "\n",
    "# plot and save its curvature diagram\n",
    "plot_curvature_diagram(u, save = True, save_name = diagsfolder + name + ' kap1_kap2.png')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
